{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_all = []\n",
    "f1_all = []\n",
    "auc_all = []\n",
    "mcc_all = []\n",
    "for i in range(1,11):\n",
    "    df_acc = read_csv('/Users/AdityaShankar/Desktop/MTP/Models/NewResults/accuracy'+str(i)+'.csv')\n",
    "    df_f1 = read_csv('/Users/AdityaShankar/Desktop/MTP/Models/NewResults/f1_score'+str(i)+'.csv')\n",
    "    df_auc = read_csv('/Users/AdityaShankar/Desktop/MTP/Models/NewResults/auc_score'+str(i)+'.csv')\n",
    "    df_mcc = read_csv('/Users/AdityaShankar/Desktop/MTP/Models/NewResults/mcc_score'+str(i)+'.csv')\n",
    "    acc_all.append(df_acc.values)\n",
    "    f1_all.append(df_f1.values)\n",
    "    auc_all.append(df_auc.values)\n",
    "    mcc_all.append(df_mcc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = iterations, y = dataset, z= model\n",
    "# for one dataset y consts,\n",
    "def getResult(metrix):\n",
    "    overallwins =  [0,0,0,0,0,0,0,0]\n",
    "    datasetWiseWins = []\n",
    "    for y in range(22):\n",
    "        modelWiseScore = [] #2d array\n",
    "        winresult = [] # dataset*model\n",
    "        for z in range(1,9):\n",
    "            modelScore = []\n",
    "            for x in range(10):\n",
    "                modelScore.append(metrix[x][y][z])\n",
    "            modelWiseScore.append(modelScore)\n",
    "\n",
    "        for i in range(len(modelWiseScore)):\n",
    "            totalStatWins = 0\n",
    "            for j in range(len(modelWiseScore)):\n",
    "                if(i!=j):\n",
    "                    modeli = modelWiseScore[i]\n",
    "                    modelj = modelWiseScore[j]\n",
    "                    wins = 0 #one-on-one win of ith model on every jth model\n",
    "                    for k in range(10):\n",
    "                        if(modeli[k]>modelj[k]):\n",
    "                            wins+=1\n",
    "                    res = stats.wilcoxon(modeli, modelj)\n",
    "                    if(wins>5 and res.pvalue<0.05):  # in 1v1 model should have better score in atleast half of the iteration\n",
    "                        totalStatWins+= 1\n",
    "                        #print(\"model\"+str(i)+\" wins against model\"+str(j))\n",
    "            #print(\"total wins of model\"+str(i),totalStatWins)\n",
    "            winresult.append(totalStatWins)\n",
    "\n",
    "            overallwins[i]+= totalStatWins\n",
    "        #print(\"Data set\"+str(y)+\" results\\n\",winresult)\n",
    "        datasetWiseWins.append(winresult)\n",
    "\n",
    "    #print(datasetWiseWins)\n",
    "    datasetWiseWins.append(overallwins)\n",
    "    return datasetWiseWins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_res = getResult(acc_all)\n",
    "f1_res = getResult(f1_all)\n",
    "auc_res = getResult(auc_all)\n",
    "mcc_res = getResult(mcc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 0, 7, 1, 3, 3, 3],\n",
       " [0, 3, 3, 7, 0, 0, 3, 3],\n",
       " [2, 1, 6, 0, 3, 1, 3, 3],\n",
       " [3, 1, 3, 0, 7, 1, 5, 5],\n",
       " [2, 2, 4, 1, 3, 0, 4, 4],\n",
       " [0, 1, 3, 0, 2, 0, 6, 6],\n",
       " [1, 4, 1, 0, 4, 1, 5, 4],\n",
       " [2, 1, 4, 0, 2, 2, 5, 4],\n",
       " [0, 1, 0, 1, 1, 2, 6, 6],\n",
       " [1, 3, 3, 0, 3, 1, 4, 4],\n",
       " [4, 1, 2, 0, 4, 1, 4, 4],\n",
       " [2, 1, 3, 0, 4, 2, 5, 5],\n",
       " [0, 1, 0, 5, 0, 2, 6, 6],\n",
       " [1, 5, 3, 1, 2, 0, 5, 5],\n",
       " [1, 1, 0, 2, 1, 1, 1, 1],\n",
       " [1, 1, 7, 0, 1, 2, 3, 4],\n",
       " [0, 0, 0, 7, 1, 4, 3, 2],\n",
       " [5, 0, 2, 0, 2, 6, 1, 2],\n",
       " [0, 3, 4, 4, 0, 0, 6, 6],\n",
       " [1, 0, 1, 1, 0, 1, 3, 2],\n",
       " [1, 1, 7, 0, 4, 2, 3, 3],\n",
       " [2, 0, 7, 1, 2, 2, 2, 2],\n",
       " [30, 34, 63, 37, 47, 34, 86, 84]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 0, 7, 1, 3, 3, 3],\n",
       " [0, 4, 1, 6, 0, 0, 3, 3],\n",
       " [2, 1, 4, 0, 0, 0, 3, 3],\n",
       " [2, 0, 0, 0, 5, 3, 4, 5],\n",
       " [1, 2, 3, 1, 1, 0, 6, 6],\n",
       " [0, 0, 0, 0, 0, 0, 6, 6],\n",
       " [0, 4, 0, 2, 2, 2, 5, 5],\n",
       " [1, 1, 5, 0, 2, 2, 5, 5],\n",
       " [0, 2, 1, 2, 1, 3, 6, 6],\n",
       " [1, 4, 2, 0, 3, 1, 4, 5],\n",
       " [3, 1, 0, 2, 4, 3, 5, 5],\n",
       " [0, 1, 2, 0, 1, 5, 5, 5],\n",
       " [0, 2, 0, 5, 1, 3, 5, 5],\n",
       " [0, 7, 0, 4, 1, 0, 4, 4],\n",
       " [2, 3, 0, 3, 1, 4, 1, 1],\n",
       " [1, 1, 7, 0, 1, 2, 4, 4],\n",
       " [0, 0, 1, 7, 1, 3, 4, 3],\n",
       " [2, 0, 0, 1, 0, 4, 0, 0],\n",
       " [0, 3, 0, 7, 0, 3, 4, 3],\n",
       " [1, 0, 0, 2, 0, 1, 2, 4],\n",
       " [0, 1, 3, 1, 3, 3, 3, 3],\n",
       " [1, 0, 7, 1, 1, 2, 4, 4],\n",
       " [18, 40, 36, 51, 29, 47, 86, 88]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 0, 7, 1, 3, 3, 3],\n",
       " [0, 6, 0, 6, 0, 1, 4, 4],\n",
       " [0, 0, 1, 5, 0, 0, 5, 5],\n",
       " [1, 1, 0, 4, 2, 7, 3, 3],\n",
       " [0, 2, 0, 3, 0, 3, 6, 6],\n",
       " [0, 1, 0, 4, 0, 4, 6, 6],\n",
       " [0, 4, 0, 5, 0, 2, 4, 4],\n",
       " [0, 3, 3, 0, 0, 5, 4, 4],\n",
       " [0, 3, 1, 4, 1, 3, 6, 6],\n",
       " [2, 5, 1, 0, 2, 0, 4, 5],\n",
       " [2, 1, 0, 3, 2, 3, 5, 5],\n",
       " [0, 1, 1, 4, 0, 5, 5, 5],\n",
       " [0, 3, 0, 5, 2, 3, 4, 4],\n",
       " [0, 7, 0, 5, 1, 2, 2, 2],\n",
       " [3, 3, 0, 3, 1, 5, 1, 1],\n",
       " [1, 1, 6, 0, 1, 2, 3, 3],\n",
       " [0, 0, 1, 7, 1, 4, 4, 2],\n",
       " [1, 1, 0, 7, 0, 0, 1, 1],\n",
       " [0, 3, 0, 7, 0, 6, 3, 3],\n",
       " [2, 0, 0, 2, 0, 1, 2, 4],\n",
       " [0, 1, 1, 3, 1, 1, 2, 2],\n",
       " [1, 0, 7, 1, 1, 1, 5, 5],\n",
       " [14, 49, 22, 85, 16, 61, 82, 83]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3, 0, 7, 1, 3, 3, 3],\n",
       " [0, 4, 0, 6, 0, 0, 4, 3],\n",
       " [0, 0, 1, 1, 0, 0, 6, 5],\n",
       " [1, 1, 0, 2, 3, 4, 3, 3],\n",
       " [0, 2, 0, 0, 0, 0, 6, 6],\n",
       " [0, 0, 0, 2, 0, 0, 6, 6],\n",
       " [0, 5, 0, 3, 1, 2, 5, 5],\n",
       " [0, 1, 4, 0, 1, 3, 5, 4],\n",
       " [0, 2, 1, 4, 1, 3, 6, 6],\n",
       " [1, 4, 2, 0, 2, 1, 4, 5],\n",
       " [2, 1, 0, 2, 3, 2, 5, 4],\n",
       " [0, 0, 1, 0, 0, 5, 5, 5],\n",
       " [0, 2, 0, 5, 1, 3, 5, 5],\n",
       " [0, 7, 0, 4, 0, 2, 2, 3],\n",
       " [2, 3, 0, 3, 1, 4, 1, 1],\n",
       " [1, 1, 7, 0, 1, 2, 4, 4],\n",
       " [0, 0, 1, 7, 1, 4, 4, 2],\n",
       " [1, 1, 0, 6, 0, 0, 1, 1],\n",
       " [0, 3, 0, 7, 0, 4, 4, 3],\n",
       " [1, 0, 0, 1, 0, 1, 2, 4],\n",
       " [0, 1, 2, 1, 3, 2, 1, 2],\n",
       " [1, 0, 7, 1, 1, 2, 5, 5],\n",
       " [10, 41, 26, 62, 20, 47, 87, 85]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DF_mean_acc = pd.DataFrame(acc_res)\n",
    "DF_mean_f1 = pd.DataFrame(f1_res)\n",
    "DF_mean_auc = pd.DataFrame(auc_res)\n",
    "DF_mean_mcc = pd.DataFrame(mcc_res)\n",
    "DF_mean_acc.to_csv(\"NewResults/Wilcoxon_accuracy.csv\")\n",
    "DF_mean_f1.to_csv(\"NewResults/Wilcoxon_f1_score.csv\")\n",
    "DF_mean_auc.to_csv(\"NewResults/Wilcoxon_auc_score.csv\")\n",
    "DF_mean_mcc.to_csv(\"NewResults/Wilcoxon_mcc_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overallwins =  [0,0,0,0,0,0,0,0]\n",
    "# totalStatWins = 0\n",
    "# totalStatLoses = 0\n",
    "# totalStatDraw = 0\n",
    "# for y in range(22):\n",
    "#     modelWiseScore = [] #2d array\n",
    "#     for z in range(1,9):\n",
    "#         modelScore = []\n",
    "#         for x in range(10):\n",
    "#             modelScore.append(acc_all[x][y][z])\n",
    "#         modelWiseScore.append(modelScore)\n",
    "\n",
    "#     modeli = modelWiseScore[4]\n",
    "#     modelj = modelWiseScore[6]\n",
    "#     print(modeli)\n",
    "#     print(modelj)\n",
    "#     wins = 0 #one-on-one win of ith model on every jth model\n",
    "#     loses = 0\n",
    "#     draw = 0\n",
    "#     for k in range(10):\n",
    "#         if(modeli[k]>modelj[k]):\n",
    "#             wins+=1\n",
    "#         elif(modeli[k]<modelj[k]):\n",
    "#             loses+= 1\n",
    "#         else:\n",
    "#             draw += 1\n",
    "#     res = stats.wilcoxon(modeli, modelj)\n",
    "\n",
    "#     if(wins>5 and res.pvalue<0.05):  # in 1v1 model should have better score in atleast half of the iteration\n",
    "#         totalStatWins+= 1\n",
    "#     elif(loses>5 and res.pvalue<0.05):\n",
    "#         totalStatLoses+= 1\n",
    "#     else:\n",
    "#         totalStatDraw+= 1\n",
    "    \n",
    "#     print(wins,loses,draw)\n",
    "#     print(totalStatWins,totalStatLoses, totalStatDraw)\n",
    "#     print(\"Data set\"+str(y)+\" results\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(meanacc)\n",
    "# df.to_csv(\"Results/mean_auc_new_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
