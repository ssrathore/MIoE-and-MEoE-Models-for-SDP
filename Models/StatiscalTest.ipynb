{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "dt_acc = [0.662,0.79,0.823,0.815,0.863,0.857,0.826,0.891,0.769,0.842,0.912,0.878,0.758,0.737,0.817,0.79,0.778,0.825,0.901,0.717,0.848,0.736]\n",
    "dt_f1 = [0.658,0.694,0.587,0.624,0.511,0.721,0.648,0.689,0.611,0.758,0.816,0.625,0.664,0.537,0.515,0.707,0.762,0.584,0.715,0.693,0.614,0.566]\n",
    "dt_auc = [0.657,0.714,0.595,0.649,0.531,0.721,0.665,0.714,0.6,0.756,0.798,0.612,0.656,0.537,0.515,0.713,0.756,0.58,0.691,0.717,0.6,0.566]\n",
    "\n",
    "svm_acc = [0.631,0.835,0.89,0.879,0.957,0.851,0.869,0.915,0.778,0.789,0.85,0.898,0.812,0.789,0.873,0.806,0.593,0.889,0.89,0.696,0.862,0.802]\n",
    "svm_f1 = [0.539,0.641,0.471,0.468,0.489,0.493,0.465,0.478,0.438,0.441,0.46,0.473,0.7,0.441,0.466,0.61,0.372,0.581,0.471,0.41,0.463,0.445]\n",
    "svm_auc= [0.6,0.616,0.5,0.498,0.5,0.516,0.498,0.5,0.5,0.498,0.5,0.5,0.675,0.5,0.5,0.597,0.5,0.563,0.5,0.5,0.496,0.493]\n",
    "\n",
    "log_acc = [0.708,0.84,0.887,0.871,0.935,0.873,0.878,0.927,0.759,0.863,0.891,0.901,0.805,0.783,0.873,0.774,0.889,0.841,0.901,0.739,0.876,0.824]\n",
    "log_f1 = [0.701,0.717,0.565,0.565,0.637,0.697,0.623,0.606,0.569,0.754,0.769,0.567,0.685,0.783,0.466,0.638,0.886,0.598,0.633,0.617,0.591,0.662]\n",
    "log_auc = [0.7,0.697,0.551,0.553,0.648,0.665,0.596,0.571,0.564,0.72,0.749,0.551,0.662,0.506,0.5,0.626,0.892,0.589,0.599,0.612,0.571,0.643]\n",
    "\n",
    "impMe_acc = [0.785,0.86,0.88,0.874,0.95,0.889,0.854,0.927,0.84,0.849,0.918,0.909,0.805,0.817,0.873,0.839,0.815,0.857,0.901,0.696,0.876,0.835]\n",
    "impMe_f1 = [0.782,0.752,0.576,0.58,0.669,0.749,0.674,0.73,0.716,0.724,0.81,0.595,0.685,0.6,0.466,0.757,0.805,0.614,0.604,0.625,0.591,0.627]\n",
    "impMe_auc = [0.781,0.728,0.561,0.564,0.655,0.718,0.675,0.701,0.684,0.692,0.765,0.568,0.662,0.587,0.5,0.744,0.801,0.598,0.576,0.621,0.571,0.604]\n",
    "\n",
    "expMe_acc = [0.769,0.855,0.873,0.879,0.95,0.894,0.837,0.927,0.825,0.859,0.898,0.904,0.819,0.806,0.873,0.823,0.815,0.889,0.901,0.652,0.862,0.824]\n",
    "expMe_f1 = [0.766,0.74,0.553,0.598,0.598,0.765,0.652,0.73,0.687,0.736,0.744,0.57,0.722,0.558,0.466,0.74,0.805,0.651,0.604,0.604,0.578,0.616]\n",
    "expMe_auc = [0.764,0.716,0.544,0.577,0.576,0.736,0.659,0.701,0.66,0.699,0.697,0.552,0.697,0.56,0.5,0.734,0.801,0.616,0.576,0.609,0.563,0.597]\n",
    "\n",
    "bagging_acc = [0.769,0.805,0.88,0.877,0.928,0.912,0.9,0.939,0.849,0.88,0.952,0.909,0.792,0.789,0.859,0.823,0.852,0.841,0.89,0.696,0.862,0.846]\n",
    "bagging_f1 = [0.766,0.686,0.559,0.607,0.624,0.817,0.731,0.791,0.743,0.797,0.897,0.628,0.633,0.561,0.462,0.752,0.847,0.539,0.557,0.553,0.546,0.664]\n",
    "bagging_auc = [0.764,0.685,0.547,0.586,0.644,0.797,0.695,0.772,0.713,0.768,0.86,0.592,0.618,0.559,0.492,0.759,0.847,0.535,0.546,0.56,0.541,0.634]\n",
    "\n",
    "adaboost_acc = [0.8,0.84,0.873,0.866,0.935,0.902,0.887,0.939,0.84,0.866,0.918,0.912,0.839,0.8,0.873,0.839,0.852,0.873,0.907,0.696,0.869,0.857]\n",
    "adaboost_f1 = [0.795,0.735,0.613,0.595,0.637,0.802,0.694,0.775,0.756,0.762,0.819,0.647,0.776,0.536,0.466,0.769,0.85,0.566,0.612,0.625,0.584,0.677]\n",
    "adaboost_auc = [0.793,0.726,0.597,0.579,0.648,0.791,0.663,0.74,0.745,0.728,0.783,0.606,0.762,0.547,0.5,0.769,0.861,0.553,0.579,0.621,0.567,0.64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null hypothesis rejected, model's performance is significantly different :  9.198092576774452e-05 Total Wins:  21\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.005721317426002655 Total Wins:  16\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.13586719981197154 Total Wins:  17\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.0548384716322051 Total Wins:  17\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.8562106793029811 Total Wins:  13\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.12387657734127984 Total Wins:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdityaShankar\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2958: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "#test against implicit ME\n",
    "acc_test = [dt_acc, svm_acc, log_acc, expMe_acc,bagging_acc, adaboost_acc]\n",
    "\n",
    "for model_acc in acc_test:\n",
    "    wins = 0\n",
    "    for i in range(len(model_acc )):\n",
    "        if(impMe_acc[i]>= model_acc [i]):\n",
    "            wins = wins + 1\n",
    "    res = stats.wilcoxon(impMe_acc, model_acc)\n",
    "    if(res.pvalue<0.05):\n",
    "        print(\"Null hypothesis rejected, model's performance is significantly different : \",res.pvalue, \"Total Wins: \", wins)\n",
    "    else:\n",
    "        print(\"Failed to reject null hypothesis and there is no significant difference in model performance: \",res.pvalue,\"Total Wins: \", wins)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.20992755889892578 Total Wins:  13\n",
      "Null hypothesis rejected, model's performance is significantly different :  6.898751069615867e-05 Total Wins:  21\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.11189633370567016 Total Wins:  17\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.07769701521837134 Total Wins:  17\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  1.0 Total Wins:  12\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.04380372353657391 Total Wins:  7\n"
     ]
    }
   ],
   "source": [
    "f1_test = [dt_f1, svm_f1, log_f1, expMe_f1,bagging_f1, adaboost_f1]\n",
    "\n",
    "for model_f1 in f1_test:\n",
    "    wins = 0\n",
    "    for i in range(len(model_f1)):\n",
    "        if(impMe_f1[i]>= model_f1[i]):\n",
    "            wins = wins + 1\n",
    "    res = stats.wilcoxon(impMe_f1, model_f1)\n",
    "    if(res.pvalue<0.05):\n",
    "        print(\"Null hypothesis rejected, model's performance is significantly different : \",res.pvalue, \"Total Wins: \", wins)\n",
    "    else:\n",
    "        print(\"Failed to reject null hypothesis and there is no significant difference in model performance: \",res.pvalue,\"Total Wins: \", wins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis and there is no significant difference in model performance:  1.0 Total Wins:  11\n",
      "Null hypothesis rejected, model's performance is significantly different :  6.898751069615867e-05 Total Wins:  21\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.04011536421674723 Total Wins:  18\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.11675126302741486 Total Wins:  17\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.5445904731750488 Total Wins:  11\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.023882134259345145 Total Wins:  8\n"
     ]
    }
   ],
   "source": [
    "auc_test = [dt_auc, svm_auc, log_auc, expMe_auc,bagging_auc, adaboost_auc]\n",
    "\n",
    "for model_auc in auc_test:\n",
    "    wins = 0\n",
    "    for i in range(len( model_auc)):\n",
    "        if(impMe_auc[i]>= model_auc[i]):\n",
    "            wins = wins + 1\n",
    "    res = stats.wilcoxon(impMe_auc, model_auc)\n",
    "    if(res.pvalue<0.05):\n",
    "        print(\"Null hypothesis rejected, model's performance is significantly different : \",res.pvalue, \"Total Wins: \", wins)\n",
    "    else:\n",
    "        print(\"Failed to reject null hypothesis and there is no significant difference in model performance: \",res.pvalue,\"Total Wins: \", wins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null hypothesis rejected, model's performance is significantly different :  0.0007940135749030001 Total Wins:  20\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.02632851897314159 Total Wins:  18\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.3060456527573018 Total Wins:  16\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.0548384716322051 Total Wins:  10\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.39806292572561963 Total Wins:  11\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.01769858011393462 Total Wins:  7\n"
     ]
    }
   ],
   "source": [
    "#test against explicit ME\n",
    "acc_test = [dt_acc, svm_acc, log_acc, impMe_acc,bagging_acc, adaboost_acc]\n",
    "\n",
    "for model_acc in acc_test:\n",
    "    wins = 0\n",
    "    for i in range(len(model_acc)):\n",
    "        if(expMe_acc[i]>= model_acc[i]):\n",
    "            wins = wins + 1\n",
    "    res = stats.wilcoxon(expMe_acc, model_acc)\n",
    "    if(res.pvalue<0.05):\n",
    "        print(\"Null hypothesis rejected, model's performance is significantly different : \",res.pvalue, \"Total Wins: \", wins)\n",
    "    else:\n",
    "        print(\"Failed to reject null hypothesis and there is no significant difference in model performance: \",res.pvalue,\"Total Wins: \", wins)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.5028400421142578 Total Wins:  13\n",
      "Null hypothesis rejected, model's performance is significantly different :  5.956977907456359e-05 Total Wins:  22\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.42397347951207676 Total Wins:  12\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.07769701521837134 Total Wins:  9\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.23043872874673688 Total Wins:  8\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.0029586332612994036 Total Wins:  5\n"
     ]
    }
   ],
   "source": [
    "f1_test = [dt_f1, svm_f1, log_f1, impMe_f1,bagging_f1, adaboost_f1]\n",
    "\n",
    "for model_f1 in f1_test:\n",
    "    wins = 0\n",
    "    for i in range(len(model_f1)):\n",
    "        if(expMe_f1[i]>= model_f1[i]):\n",
    "            wins = wins + 1\n",
    "    res = stats.wilcoxon(expMe_f1, model_f1)\n",
    "    if(res.pvalue<0.05):\n",
    "        print(\"Null hypothesis rejected, model's performance is significantly different : \",res.pvalue, \"Total Wins: \", wins)\n",
    "    else:\n",
    "        print(\"Failed to reject null hypothesis and there is no significant difference in model performance: \",res.pvalue,\"Total Wins: \", wins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.5660676956176758 Total Wins:  11\n",
      "Null hypothesis rejected, model's performance is significantly different :  5.941682973416533e-05 Total Wins:  22\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.2172414463719159 Total Wins:  13\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.11675126302741486 Total Wins:  9\n",
      "Failed to reject null hypothesis and there is no significant difference in model performance:  0.16977498788033196 Total Wins:  9\n",
      "Null hypothesis rejected, model's performance is significantly different :  0.001468662742611279 Total Wins:  3\n"
     ]
    }
   ],
   "source": [
    "auc_test = [dt_auc, svm_auc, log_auc, impMe_auc,bagging_auc, adaboost_auc]\n",
    "\n",
    "for model_auc in auc_test:\n",
    "    wins = 0\n",
    "    for i in range(len( model_auc)):\n",
    "        if(expMe_auc[i]>=  model_auc[i]):\n",
    "            wins = wins + 1\n",
    "    res = stats.wilcoxon(expMe_auc, model_auc)\n",
    "    if(res.pvalue<0.05):\n",
    "        print(\"Null hypothesis rejected, model's performance is significantly different : \",res.pvalue, \"Total Wins: \", wins)\n",
    "    else:\n",
    "        print(\"Failed to reject null hypothesis and there is no significant difference in model performance: \",res.pvalue,\"Total Wins: \", wins)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
