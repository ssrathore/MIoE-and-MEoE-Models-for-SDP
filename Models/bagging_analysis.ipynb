{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_models import bagging\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def main(data,name):\n",
    "    \n",
    "    #Data Preprocessing\n",
    "    df = pd.DataFrame(data[0])\n",
    "    X= df.iloc[ : , :-1].values\n",
    "    y=[]\n",
    "    if \"AEEEM\" in name:\n",
    "        y = df['class'].str.decode(\"utf-8\").map({'buggy': 1, 'clean': 0})\n",
    "    elif \"JIRA\" in name:\n",
    "        y= df['RealBugCount'].apply(lambda x : 1 if(x > 0) else 0)\n",
    "    else:\n",
    "        y= df['defects'].apply(lambda x : 1 if(x > 0) else 0)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    st_x= StandardScaler()  \n",
    "    X_train= st_x.fit_transform(X_train) \n",
    "    X_test= st_x.transform(X_test) \n",
    "    sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "    sel_.fit(X_train, y_train)\n",
    "    sel_.get_support()\n",
    "    X_train = sel_.transform(X_train)\n",
    "    X_test = sel_.transform(X_test)\n",
    "    oversample = SMOTE()\n",
    "    X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #Models\n",
    "    bag = bagging(X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    #results\n",
    "    acc = bag[\"Accuracy\"]\n",
    "    f1 = bag[\"F1_score\"]\n",
    "    auc = bag[\"AUC_score\"]\n",
    "    mcc = bag[\"MCC\"]\n",
    "    res = {\n",
    "        \"acc\" : acc,\n",
    "        \"f1\" : f1,\n",
    "        \"auc\" : auc,\n",
    "        \"mcc\" : mcc\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "datasets.append({\"path\": '../dataSet/AEEEM/EQ.arff', \"name\" : 'AEEEM-EQ' })\n",
    "datasets.append({\"path\": '../dataSet/AEEEM/JDT.arff', \"name\" : 'AEEEM-JDT' })\n",
    "datasets.append({\"path\": '../dataSet/AEEEM/Lucene.arff', \"name\" : 'AEEEM-LUCENE' })\n",
    "datasets.append({\"path\": '../dataSet/AEEEM/Mylyn.arff', \"name\" : 'AEEEM-MYLYN' })\n",
    "datasets.append({\"path\": '../dataSet/AEEEM/PDE.arff', \"name\" : 'AEEEM-PDE' })\n",
    "\n",
    "datasets.append({\"path\": '../dataSet/JIRA/activemq-5.0.0.arff', \"name\" : 'JIRA-ACTIVEMQ' })\n",
    "datasets.append({\"path\": '../dataSet/JIRA/derby-10.5.1.1.arff', \"name\" : 'JIRA-DERBY' })\n",
    "datasets.append({\"path\": '../dataSet/JIRA/groovy-1_6_BETA_1.arff', \"name\" : 'JIRA-GROOVY' })\n",
    "datasets.append({\"path\": '../dataSet/JIRA/hbase-0.94.0.arff', \"name\" : 'JIRA-HBASE' })\n",
    "datasets.append({\"path\": '../dataSet/JIRA/hive-0.9.0.arff', \"name\" : 'JIRA-HIVE' })\n",
    "datasets.append({\"path\": '../dataSet/JIRA/jruby-1.1.arff', \"name\" : 'JIRA-JRUBY' })\n",
    "datasets.append({\"path\": '../dataSet/JIRA/wicket-1.3.0-beta2.arff', \"name\" : 'JIRA-WICKET' })\n",
    "\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/ant-1.7.arff', \"name\" : 'PROMISE-ANT' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/camel-1.4.arff', \"name\" : 'PROMISE-CAMEL' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/ivy-2.0.arff', \"name\" : 'PROMISE-IVY' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/jedit-4.0.arff', \"name\" : 'PROMISE-JEDIT' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/log4j-1.0.arff', \"name\" : 'PROMISE-LOG' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/poi-2.0.arff', \"name\" : 'PROMISE-POI' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/tomcat.arff', \"name\" : 'PROMISE-TOMCAT' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/velocity-1.6.arff', \"name\" : 'PROMISE-VELOCITY' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/xalan-2.4.arff', \"name\" : 'PROMISE-XALAN' })\n",
    "datasets.append({\"path\": '../dataSet/PROMISE/xerces-1.3.arff', \"name\" : 'PROMISE-XERCES' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.716923076923077, 0.8004999999999999, 0.8266187050359711, 0.8407506702412869, 0.8196666666666668, 0.8681697612732096, 0.8491682070240296, 0.8909090909090909, 0.8122641509433961, 0.8524647887323944, 0.8911564625850339, 0.875070821529745, 0.7691275167785235, 0.7205714285714285, 0.8140845070422535, 0.7532258064516129, 0.7666666666666667, 0.73015873015873, 0.8517441860465116, 0.6434782608695653, 0.8082758620689656, 0.7802197802197803]\n",
      "0.8036915975789973\n"
     ]
    }
   ],
   "source": [
    "acc_all = []\n",
    "f1_all = []\n",
    "auc_all = []\n",
    "mcc_all = []\n",
    "for i in range(10):\n",
    "    acc = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "    mcc = []\n",
    "    for singledata in datasets:\n",
    "        data = arff.loadarff(singledata[\"path\"])\n",
    "        res = main(data,singledata[\"name\"])    \n",
    "        acc.append(res[\"acc\"])\n",
    "        f1.append(res[\"f1\"])\n",
    "        auc.append(res[\"auc\"])\n",
    "        mcc.append(res[\"mcc\"])\n",
    "    acc_all.append(acc)\n",
    "    f1_all.append(f1)\n",
    "    auc_all.append(auc)\n",
    "    mcc_all.append(mcc)\n",
    "finalacc = []\n",
    "for y in range(22):\n",
    "    temp = []\n",
    "    for x in range(10):\n",
    "        temp.append(acc_all[x][y])\n",
    "    ans = np.mean(temp)\n",
    "    finalacc.append(ans)\n",
    "print(finalacc)\n",
    "print(np.mean(finalacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
